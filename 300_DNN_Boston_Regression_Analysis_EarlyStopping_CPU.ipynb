{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "300_DNN_Boston_Regression_Analysis_EarlyStopping_CPU.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yVyXm7wqHLIK"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNo5uiwV6GsUSAT/ajz6FgP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boramdv/TIL/blob/master/300_DNN_Boston_Regression_Analysis_EarlyStopping_CPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z5EJNf7zwZn"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6itYel1PAFSn",
        "outputId": "43579ece-5bdd-4188-fe0f-bc2ea3d18e83"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gtI773eBAH7X",
        "outputId": "055fc3db-5b3c-4401-bfcf-368914aba0ac"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVbALwBBAP__"
      },
      "source": [
        "# 1. Boston_Housing_Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxmmcdyZAObj",
        "outputId": "a1b4e56e-5f1f-446f-ac98-5214ffe4295d"
      },
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "# 뒤에 Validation set을 split 하기 위해 train data 이름을 아래 일반적인 방식과 다르게 지정\n",
        "# (X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "(train_data, train_targets), (X_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHOoiHZ2Ar4Q",
        "outputId": "fcb180c0-2f7a-4440-c12c-a883210acfb6"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(train_targets[:10])\n",
        "print(y_test[:10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(102, 13)\n",
            "[15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4]\n",
            "[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo7Mx9QkI9Yi"
      },
      "source": [
        "# 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otfmsl93A8Wp"
      },
      "source": [
        "- Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBnaPOTwBYMh",
        "outputId": "3f6855d2-b2be-445d-d17a-e484c378ebeb"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress = True, precision = 9, linewidth = np.inf)\n",
        "\n",
        "print(train_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1.23247   0.        8.14    ...  21.      396.9      18.72   ]\n",
            " [  0.02177  82.5       2.03    ...  14.7     395.38      3.11   ]\n",
            " [  4.89822   0.       18.1     ...  20.2     375.52      3.26   ]\n",
            " ...\n",
            " [  0.03466  35.        6.06    ...  16.9     362.25      7.83   ]\n",
            " [  2.14918   0.       19.58    ...  14.7     261.95     15.79   ]\n",
            " [  0.01439  60.        2.93    ...  15.6     376.7       4.38   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmTnEWjmA0rH"
      },
      "source": [
        "# axis = 0 의 의미\n",
        "# https://nov19.tistory.com/104\n",
        "\n",
        "mean = train_data.mean(axis = 0)\n",
        "std = train_data.std(axis = 0)\n",
        "\n",
        "train_data = train_data - mean\n",
        "train_data = train_data / std\n",
        "\n",
        "X_test = X_test - mean\n",
        "X_test = X_test / std"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK5nXFaqDkMc",
        "outputId": "36e0d0cc-3e2a-46f5-a4db-248dd8e7430f"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.272246334, -0.483615471, -0.435761611, ...,  1.148500439,  0.448077135,  0.825220199],\n",
              "       [-0.403426512,  2.991784194, -1.333911616, ..., -1.718189094,  0.431905993, -1.329202394],\n",
              "       [ 0.1249402  , -0.483615471,  1.028325795, ...,  0.784476371,  0.220617263, -1.308500063],\n",
              "       ...,\n",
              "       [-0.402029872,  0.990796508, -0.741514804, ..., -0.717122908,  0.079438942, -0.677769041],\n",
              "       [-0.172920175, -0.483615471,  1.245880952, ..., -1.718189094, -0.987643619,  0.420834664],\n",
              "       [-0.40422614 ,  2.043947921, -1.201614561, ..., -1.308662018,  0.233171175, -1.153922657]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZL9TW00FhFQ",
        "outputId": "aca39c85-a718-4cc6-80fb-795886119c5d"
      },
      "source": [
        "# mean = 0, std = 1\n",
        "train_data.mean(axis = 0), train_data.std(axis = 0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.,  0.,  0., -0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfY2zoQdDnPL",
        "outputId": "2361c8f6-c83e-4d4d-d4bc-be61edbd80cb"
      },
      "source": [
        "X_test[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.553693545, -0.483615471,  1.028325795, -0.256832748,  1.038380668,  0.235458154,  1.110488282, -0.939769356,  1.675885772,  1.565287499,  0.784476371, -3.484595533,  2.250920736],\n",
              "       [-0.39242675 , -0.483615471, -0.16087773 , -0.256832748, -0.088400606, -0.499474361,  0.856063288, -0.683962347, -0.39603557 ,  0.157078413, -0.307595832,  0.427331262,  0.478801191],\n",
              "       [-0.399829269, -0.483615471, -0.869401957, -0.256832748, -0.361559702, -0.39790979 , -0.84607575 ,  0.52864277 , -0.511142311, -1.094662998,  0.784476371,  0.448077135, -0.414159358],\n",
              "       [-0.26780504 , -0.483615471,  1.245880952,  3.893584467,  0.406700257, -0.024095747,  0.845312937, -0.957671408, -0.511142311, -0.017443226, -1.718189094, -0.168766802, -0.999345252],\n",
              "       [-0.398037149, -0.483615471, -0.972299666, -0.256832748, -0.924950339, -0.206065602, -0.437562381,  0.003614542, -0.741355794, -0.956249284,  0.010925227,  0.429459044, -0.593579561],\n",
              "       [-0.375493705, -0.483615471, -0.207916683, -0.256832748,  0.235975822, -0.481136313, -0.946412367, -0.670005651, -0.39603557 , -0.089659077,  0.329446286,  0.448077135,  0.117200474],\n",
              "       [-0.402481694,  1.833317639, -1.076667343, -0.256832748, -0.626182577,  0.856130528, -1.466012705,  1.343950553, -0.511142311, -0.216036815, -0.398601849,  0.353071678, -1.122179083],\n",
              "       [-0.401937774,  0.569535943, -0.917910877, -0.256832748, -1.12128344 , -0.141177127, -0.799490892,  0.818873008, -0.626249053, -0.751637707,  0.23844027 ,  0.381477565, -0.721934014],\n",
              "       [-0.395709776, -0.483615471,  2.138151088, -0.256832748,  0.201830935, -0.431764647,  0.856063288, -0.815392013, -0.856462535, -1.311310549,  0.283943278,  0.247959259,  0.716187922],\n",
              "       [-0.019116374, -0.483615471,  1.028325795, -0.256832748,  0.193294713,  0.239690011,  0.21462563 , -0.416122002,  1.675885772,  1.565287499,  0.784476371,  0.410521786,  0.223472441]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk-c7JKkFmBf",
        "outputId": "310ffcf7-af88-461b-b5e7-fdd97c9e7b64"
      },
      "source": [
        "X_test.mean(axis = 0), X_test.std(axis = 0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.070728597, -0.024358854,  0.023588751,  0.1500709  , -0.112678625,  0.122829905, -0.077460727,  0.133999849,  0.0621344  ,  0.069817593, -0.046176587,  0.099794721, -0.060081841]),\n",
              " array([0.579316943, 0.904316656, 1.03622933 , 1.234199874, 0.934494178, 0.94374857 , 1.035341817, 1.167962123, 1.004768412, 1.062287782, 0.917716328, 0.837808078, 0.919528367]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVyXm7wqHLIK"
      },
      "source": [
        "## Sklearn - StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrb8XBETDtgM",
        "outputId": "d36180ef-cd85-468a-c265-6ac477ebc38f"
      },
      "source": [
        "# 사이킷런 Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_data_scaled = scaler.fit_transform(train_data)\n",
        "train_data_scaled"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.272246334, -0.483615471, -0.435761611, ...,  1.148500439,  0.448077135,  0.825220199],\n",
              "       [-0.403426512,  2.991784194, -1.333911616, ..., -1.718189094,  0.431905993, -1.329202394],\n",
              "       [ 0.1249402  , -0.483615471,  1.028325795, ...,  0.784476371,  0.220617263, -1.308500063],\n",
              "       ...,\n",
              "       [-0.402029872,  0.990796508, -0.741514804, ..., -0.717122908,  0.079438942, -0.677769041],\n",
              "       [-0.172920175, -0.483615471,  1.245880952, ..., -1.718189094, -0.987643619,  0.420834664],\n",
              "       [-0.40422614 ,  2.043947921, -1.201614561, ..., -1.308662018,  0.233171175, -1.153922657]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB9YKQm0FX7O",
        "outputId": "4a2ddcc5-0e35-4158-a805-1c49fa320c0f"
      },
      "source": [
        "train_data_scaled.mean(axis = 0), train_data_scaled.std(axis = 0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.,  0., -0.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kimjaH7jEgAW",
        "outputId": "d809a2f7-8b19-4ddc-e8fc-37e772a9c872"
      },
      "source": [
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_scaled"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.553693545, -0.483615471,  1.028325795, ...,  0.784476371, -3.484595533,  2.250920736],\n",
              "       [-0.39242675 , -0.483615471, -0.16087773 , ..., -0.307595832,  0.427331262,  0.478801191],\n",
              "       [-0.399829269, -0.483615471, -0.869401957, ...,  0.784476371,  0.448077135, -0.414159358],\n",
              "       ...,\n",
              "       [-0.207095066, -0.483615471,  1.245880952, ..., -1.718189094,  0.370519489, -1.493440888],\n",
              "       [-0.366986009, -0.483615471, -0.720935262, ..., -0.489607866,  0.392754808, -0.418299824],\n",
              "       [-0.088967895, -0.483615471,  1.245880952, ..., -1.718189094, -1.219465443, -0.40449827 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9lQrLd1FLTW",
        "outputId": "8f378ee3-27d1-4477-ab5b-1ea052cf6c67"
      },
      "source": [
        "X_test_scaled.mean(axis = 0), X_test_scaled.std(axis = 0)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.070728597, -0.024358854,  0.023588751,  0.1500709  , -0.112678625,  0.122829905, -0.077460727,  0.133999849,  0.0621344  ,  0.069817593, -0.046176587,  0.099794721, -0.060081841]),\n",
              " array([0.579316943, 0.904316656, 1.03622933 , 1.234199874, 0.934494178, 0.94374857 , 1.035341817, 1.167962123, 1.004768412, 1.062287782, 0.917716328, 0.837808078, 0.919528367]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxniYybtHkUQ",
        "outputId": "1068a31a-88d0-44e5-f9b7-2a5207a77f25"
      },
      "source": [
        "# 직접 scaling 방식과 StandardScaler 방식의 X_test의 data 비교\n",
        "X_test[:10], X_test_scaled[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.553693545, -0.483615471,  1.028325795, -0.256832748,  1.038380668,  0.235458154,  1.110488282, -0.939769356,  1.675885772,  1.565287499,  0.784476371, -3.484595533,  2.250920736],\n",
              "        [-0.39242675 , -0.483615471, -0.16087773 , -0.256832748, -0.088400606, -0.499474361,  0.856063288, -0.683962347, -0.39603557 ,  0.157078413, -0.307595832,  0.427331262,  0.478801191],\n",
              "        [-0.399829269, -0.483615471, -0.869401957, -0.256832748, -0.361559702, -0.39790979 , -0.84607575 ,  0.52864277 , -0.511142311, -1.094662998,  0.784476371,  0.448077135, -0.414159358],\n",
              "        [-0.26780504 , -0.483615471,  1.245880952,  3.893584467,  0.406700257, -0.024095747,  0.845312937, -0.957671408, -0.511142311, -0.017443226, -1.718189094, -0.168766802, -0.999345252],\n",
              "        [-0.398037149, -0.483615471, -0.972299666, -0.256832748, -0.924950339, -0.206065602, -0.437562381,  0.003614542, -0.741355794, -0.956249284,  0.010925227,  0.429459044, -0.593579561],\n",
              "        [-0.375493705, -0.483615471, -0.207916683, -0.256832748,  0.235975822, -0.481136313, -0.946412367, -0.670005651, -0.39603557 , -0.089659077,  0.329446286,  0.448077135,  0.117200474],\n",
              "        [-0.402481694,  1.833317639, -1.076667343, -0.256832748, -0.626182577,  0.856130528, -1.466012705,  1.343950553, -0.511142311, -0.216036815, -0.398601849,  0.353071678, -1.122179083],\n",
              "        [-0.401937774,  0.569535943, -0.917910877, -0.256832748, -1.12128344 , -0.141177127, -0.799490892,  0.818873008, -0.626249053, -0.751637707,  0.23844027 ,  0.381477565, -0.721934014],\n",
              "        [-0.395709776, -0.483615471,  2.138151088, -0.256832748,  0.201830935, -0.431764647,  0.856063288, -0.815392013, -0.856462535, -1.311310549,  0.283943278,  0.247959259,  0.716187922],\n",
              "        [-0.019116374, -0.483615471,  1.028325795, -0.256832748,  0.193294713,  0.239690011,  0.21462563 , -0.416122002,  1.675885772,  1.565287499,  0.784476371,  0.410521786,  0.223472441]]),\n",
              " array([[ 1.553693545, -0.483615471,  1.028325795, -0.256832748,  1.038380668,  0.235458154,  1.110488282, -0.939769356,  1.675885772,  1.565287499,  0.784476371, -3.484595533,  2.250920736],\n",
              "        [-0.39242675 , -0.483615471, -0.16087773 , -0.256832748, -0.088400606, -0.499474361,  0.856063288, -0.683962347, -0.39603557 ,  0.157078413, -0.307595832,  0.427331262,  0.478801191],\n",
              "        [-0.399829269, -0.483615471, -0.869401957, -0.256832748, -0.361559702, -0.39790979 , -0.84607575 ,  0.52864277 , -0.511142311, -1.094662998,  0.784476371,  0.448077135, -0.414159358],\n",
              "        [-0.26780504 , -0.483615471,  1.245880952,  3.893584467,  0.406700257, -0.024095747,  0.845312937, -0.957671408, -0.511142311, -0.017443226, -1.718189094, -0.168766802, -0.999345252],\n",
              "        [-0.398037149, -0.483615471, -0.972299666, -0.256832748, -0.924950339, -0.206065602, -0.437562381,  0.003614542, -0.741355794, -0.956249284,  0.010925227,  0.429459044, -0.593579561],\n",
              "        [-0.375493705, -0.483615471, -0.207916683, -0.256832748,  0.235975822, -0.481136313, -0.946412367, -0.670005651, -0.39603557 , -0.089659077,  0.329446286,  0.448077135,  0.117200474],\n",
              "        [-0.402481694,  1.833317639, -1.076667343, -0.256832748, -0.626182577,  0.856130528, -1.466012705,  1.343950553, -0.511142311, -0.216036815, -0.398601849,  0.353071678, -1.122179083],\n",
              "        [-0.401937774,  0.569535943, -0.917910877, -0.256832748, -1.12128344 , -0.141177127, -0.799490892,  0.818873008, -0.626249053, -0.751637707,  0.23844027 ,  0.381477565, -0.721934014],\n",
              "        [-0.395709776, -0.483615471,  2.138151088, -0.256832748,  0.201830935, -0.431764647,  0.856063288, -0.815392013, -0.856462535, -1.311310549,  0.283943278,  0.247959259,  0.716187922],\n",
              "        [-0.019116374, -0.483615471,  1.028325795, -0.256832748,  0.193294713,  0.239690011,  0.21462563 , -0.416122002,  1.675885772,  1.565287499,  0.784476371,  0.410521786,  0.223472441]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXq3Rv6yHpml",
        "outputId": "d2dec134-c712-4d6e-ac6c-dcd35490e7c9"
      },
      "source": [
        "# 직접 scaling 방식과 StandardScaler 방식의 X_test의 mean, std 비교\n",
        "X_test.mean(axis = 0), X_test_scaled.mean(axis = 0), X_test.std(axis = 0), X_test_scaled.std(axis = 0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.070728597, -0.024358854,  0.023588751,  0.1500709  , -0.112678625,  0.122829905, -0.077460727,  0.133999849,  0.0621344  ,  0.069817593, -0.046176587,  0.099794721, -0.060081841]),\n",
              " array([-0.070728597, -0.024358854,  0.023588751,  0.1500709  , -0.112678625,  0.122829905, -0.077460727,  0.133999849,  0.0621344  ,  0.069817593, -0.046176587,  0.099794721, -0.060081841]),\n",
              " array([0.579316943, 0.904316656, 1.03622933 , 1.234199874, 0.934494178, 0.94374857 , 1.035341817, 1.167962123, 1.004768412, 1.062287782, 0.917716328, 0.837808078, 0.919528367]),\n",
              " array([0.579316943, 0.904316656, 1.03622933 , 1.234199874, 0.934494178, 0.94374857 , 1.035341817, 1.167962123, 1.004768412, 1.062287782, 0.917716328, 0.837808078, 0.919528367]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw4t2E5iJIek"
      },
      "source": [
        "## Train & Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoccO0TAJLz2",
        "outputId": "1cc8c777-ac40-432a-e31a-bc74f74d3aad"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_targets,\n",
        "                                                      test_size = 0.2,\n",
        "                                                      random_state = 2045)\n",
        "\n",
        "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((323, 13), (81, 13), (323,), (81,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlxuiYCrI3w5"
      },
      "source": [
        "# 3. Keras Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTuGewaYH5S5"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "boston = models.Sequential(name = 'Regression')\n",
        "boston.add(layers.Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "boston.add(layers.Dense(64, activation = 'relu'))\n",
        "boston.add(layers.Dense(1))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rap0zinWJyFl",
        "outputId": "3ff3850b-8e88-4d42-afbf-109c301e61a2"
      },
      "source": [
        "boston.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Regression\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                896       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeXvvASXJzUs"
      },
      "source": [
        "boston.compile(loss = 'mse', \n",
        "               optimizer = 'rmsprop',\n",
        "               metrics = ['mae'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y8mn68AKKPRO",
        "outputId": "312f4339-f36e-41ee-b6f2-b14dd4b66b40"
      },
      "source": [
        "%%time\n",
        "\n",
        "Hist_boston = boston.fit(X_train, y_train,\n",
        "                         epochs = 500,\n",
        "                         batch_size = 1,\n",
        "                         validation_data = (X_valid, y_valid))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "323/323 [==============================] - 4s 3ms/step - loss: 200.5419 - mae: 10.4741 - val_loss: 55.3154 - val_mae: 4.6231\n",
            "Epoch 2/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 26.0932 - mae: 3.6105 - val_loss: 34.3298 - val_mae: 3.2604\n",
            "Epoch 3/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 19.0171 - mae: 2.9681 - val_loss: 28.0767 - val_mae: 2.8197\n",
            "Epoch 4/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 15.4443 - mae: 2.6279 - val_loss: 22.8580 - val_mae: 3.1070\n",
            "Epoch 5/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 14.1560 - mae: 2.5260 - val_loss: 22.9930 - val_mae: 2.5319\n",
            "Epoch 6/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 13.3465 - mae: 2.4023 - val_loss: 19.7578 - val_mae: 2.5893\n",
            "Epoch 7/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 12.9385 - mae: 2.3239 - val_loss: 21.0096 - val_mae: 2.5065\n",
            "Epoch 8/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 11.7863 - mae: 2.2606 - val_loss: 23.2487 - val_mae: 2.6302\n",
            "Epoch 9/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 11.5111 - mae: 2.2469 - val_loss: 16.6351 - val_mae: 2.3243\n",
            "Epoch 10/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 11.3209 - mae: 2.2155 - val_loss: 17.3815 - val_mae: 2.4465\n",
            "Epoch 11/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 11.2377 - mae: 2.1659 - val_loss: 20.2144 - val_mae: 2.5627\n",
            "Epoch 12/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 11.0588 - mae: 2.1681 - val_loss: 17.1996 - val_mae: 2.4595\n",
            "Epoch 13/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 10.4124 - mae: 2.1154 - val_loss: 16.6891 - val_mae: 2.2912\n",
            "Epoch 14/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 10.7081 - mae: 2.0499 - val_loss: 17.4874 - val_mae: 2.4354\n",
            "Epoch 15/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.9397 - mae: 2.0509 - val_loss: 17.0965 - val_mae: 2.3838\n",
            "Epoch 16/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.8125 - mae: 2.0457 - val_loss: 15.3766 - val_mae: 2.3929\n",
            "Epoch 17/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.9835 - mae: 2.0129 - val_loss: 18.6528 - val_mae: 2.4235\n",
            "Epoch 18/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 10.0250 - mae: 2.0143 - val_loss: 15.1685 - val_mae: 2.1997\n",
            "Epoch 19/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.5641 - mae: 2.0138 - val_loss: 14.5333 - val_mae: 2.1723\n",
            "Epoch 20/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.8040 - mae: 1.9500 - val_loss: 14.8304 - val_mae: 2.3541\n",
            "Epoch 21/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.2589 - mae: 1.9804 - val_loss: 19.5208 - val_mae: 2.7243\n",
            "Epoch 22/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.0301 - mae: 1.8937 - val_loss: 16.1946 - val_mae: 2.3458\n",
            "Epoch 23/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.0897 - mae: 1.9777 - val_loss: 14.3444 - val_mae: 2.2053\n",
            "Epoch 24/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.5371 - mae: 1.9121 - val_loss: 14.6831 - val_mae: 2.2338\n",
            "Epoch 25/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.4799 - mae: 1.9090 - val_loss: 15.3190 - val_mae: 2.3491\n",
            "Epoch 26/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.7668 - mae: 1.8712 - val_loss: 14.1456 - val_mae: 2.3600\n",
            "Epoch 27/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.0228 - mae: 1.8623 - val_loss: 15.6745 - val_mae: 2.4335\n",
            "Epoch 28/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.1531 - mae: 1.9348 - val_loss: 14.0630 - val_mae: 2.1801\n",
            "Epoch 29/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.9119 - mae: 1.9193 - val_loss: 13.8714 - val_mae: 2.1864\n",
            "Epoch 30/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.2792 - mae: 1.8340 - val_loss: 14.4569 - val_mae: 2.7061\n",
            "Epoch 31/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.4956 - mae: 1.9117 - val_loss: 13.3780 - val_mae: 2.2170\n",
            "Epoch 32/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.2354 - mae: 1.8944 - val_loss: 13.1847 - val_mae: 2.3461\n",
            "Epoch 33/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.2740 - mae: 1.8359 - val_loss: 13.2419 - val_mae: 2.2305\n",
            "Epoch 34/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.1077 - mae: 1.8503 - val_loss: 12.8076 - val_mae: 2.1701\n",
            "Epoch 35/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.6562 - mae: 1.8471 - val_loss: 13.7654 - val_mae: 2.2254\n",
            "Epoch 36/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.1708 - mae: 1.8550 - val_loss: 15.1098 - val_mae: 2.5075\n",
            "Epoch 37/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.1175 - mae: 1.7903 - val_loss: 13.5888 - val_mae: 2.1642\n",
            "Epoch 38/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.7586 - mae: 1.7510 - val_loss: 13.0577 - val_mae: 2.3790\n",
            "Epoch 39/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.6386 - mae: 1.7908 - val_loss: 15.8280 - val_mae: 2.4821\n",
            "Epoch 40/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.0823 - mae: 1.8203 - val_loss: 14.3211 - val_mae: 2.2700\n",
            "Epoch 41/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.6866 - mae: 1.7684 - val_loss: 12.2110 - val_mae: 2.1963\n",
            "Epoch 42/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.1476 - mae: 1.7584 - val_loss: 13.3007 - val_mae: 2.4268\n",
            "Epoch 43/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.2825 - mae: 1.7452 - val_loss: 13.2562 - val_mae: 2.2558\n",
            "Epoch 44/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.2733 - mae: 1.7595 - val_loss: 10.8964 - val_mae: 2.1017\n",
            "Epoch 45/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.1984 - mae: 1.7247 - val_loss: 12.8942 - val_mae: 2.3372\n",
            "Epoch 46/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.7380 - mae: 1.7189 - val_loss: 13.4802 - val_mae: 2.4386\n",
            "Epoch 47/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.9046 - mae: 1.7619 - val_loss: 12.0053 - val_mae: 2.0950\n",
            "Epoch 48/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.8045 - mae: 1.7322 - val_loss: 11.2922 - val_mae: 2.1964\n",
            "Epoch 49/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.6607 - mae: 1.7055 - val_loss: 10.6865 - val_mae: 2.1113\n",
            "Epoch 50/500\n",
            "182/323 [===============>..............] - ETA: 0s - loss: 7.8757 - mae: 1.6830"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-87ec71035195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nHist_boston = boston.fit(X_train, y_train,\\n                         epochs = 500,\\n                         batch_size = 1,\\n                         validation_data = (X_valid, y_valid))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h0bwGG8LKx2"
      },
      "source": [
        "test_mse_score, test_mae_score = boston.evaluate(X_test, y_test)\n",
        "\n",
        "print('MAE is :', test_mae_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlzacUYrLVJD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, len(Hist_boston.history['val_mae']) + 1)\n",
        "\n",
        "plt.figure(figsize = (9, 6))\n",
        "plt.plot(epochs, Hist_boston.history['val_mae'])\n",
        "plt.title('Validation MAE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BcBwAPnL03i"
      },
      "source": [
        "- 5번째 이후 MAE 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdOUW1AsLsTy"
      },
      "source": [
        "def smooth_curve(points, factor = 0.9):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "  return smoothed_points\n",
        "\n",
        "mae_history = Hist_boston.history['val_mae']\n",
        "\n",
        "mae_history = smooth_curve(mae_history[5:])\n",
        "\n",
        "plt.figure(figsize = (9, 6))\n",
        "plt.plot(range(1, len(mae_history) + 1), mae_history)\n",
        "plt.title('Validation MAE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pME-HKhUMvZT"
      },
      "source": [
        "# session 초기화\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaCcFEsJNRRC"
      },
      "source": [
        "# **Early Stopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "016c_3usNQFl"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "boston = models.Sequential(name = 'EarlyStopping')\n",
        "boston.add(layers.Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "boston.add(layers.Dense(64, activation = 'relu'))\n",
        "boston.add(layers.Dense(1))\n",
        "\n",
        "boston.compile(loss = 'mse',\n",
        "               optimizer = 'rmsprop',\n",
        "               metrics = ['mae'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRpNQ7r4OQgX"
      },
      "source": [
        "## EerlyStopping()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gPYLLRgN-4N"
      },
      "source": [
        "- monitor : 모니터링 대상 성능\n",
        "- mode : 모니터링 대상을 최소화(min - mse, mae) 또는 최대화(max - accuracy)\n",
        "- patience : 성능이 개선되지 않는 epoch 횟수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w22b2x74Ny-_"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(monitor = 'val_mae',\n",
        "                   mode = 'min',\n",
        "                   patience = 50,\n",
        "                   verbose = 1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n8NGmvAOhB8"
      },
      "source": [
        "## ModelCheckpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIKs9JFYOjaR"
      },
      "source": [
        "- 'best_boston.h5' : 최적 모델이 저장될 경로\n",
        "- save_best_only : 최적 모델만 저장할지 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olEd5BubOevI"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "mc = ModelCheckpoint('best_boston.h5',\n",
        "                     monitor = 'val_mae',\n",
        "                     mode = 'min',\n",
        "                     save_best_only = True,\n",
        "                     verbose = 1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAG6yBr2O5Zu"
      },
      "source": [
        "## Model Fit with callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FgLssFoO-hw"
      },
      "source": [
        "- callbacks : EarlyStopping()과 ModelCheckpoint() 객체 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BifOJ6QO3BP",
        "outputId": "bd9b3384-1203-4a65-93d8-d177472aa8df"
      },
      "source": [
        "%%time\n",
        "\n",
        "Hist_boston = boston.fit(X_train, y_train,\n",
        "                         epochs = 500,\n",
        "                         batch_size = 1,\n",
        "                         validation_data = (X_valid, y_valid),\n",
        "                         callbacks = [es, mc],\n",
        "                         verbose = 1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 170.6202 - mae: 9.4967 - val_loss: 44.4083 - val_mae: 4.0431\n",
            "\n",
            "Epoch 00001: val_mae improved from inf to 4.04310, saving model to best_boston.h5\n",
            "Epoch 2/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 25.7934 - mae: 3.5278 - val_loss: 29.0793 - val_mae: 3.3476\n",
            "\n",
            "Epoch 00002: val_mae improved from 4.04310 to 3.34755, saving model to best_boston.h5\n",
            "Epoch 3/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 18.7266 - mae: 2.8914 - val_loss: 21.2768 - val_mae: 2.7429\n",
            "\n",
            "Epoch 00003: val_mae improved from 3.34755 to 2.74289, saving model to best_boston.h5\n",
            "Epoch 4/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 15.4978 - mae: 2.6268 - val_loss: 20.1688 - val_mae: 2.5384\n",
            "\n",
            "Epoch 00004: val_mae improved from 2.74289 to 2.53842, saving model to best_boston.h5\n",
            "Epoch 5/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 13.8034 - mae: 2.4730 - val_loss: 18.6137 - val_mae: 2.6844\n",
            "\n",
            "Epoch 00005: val_mae did not improve from 2.53842\n",
            "Epoch 6/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 13.0291 - mae: 2.4145 - val_loss: 18.2010 - val_mae: 2.4755\n",
            "\n",
            "Epoch 00006: val_mae improved from 2.53842 to 2.47551, saving model to best_boston.h5\n",
            "Epoch 7/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 12.2653 - mae: 2.3209 - val_loss: 16.9933 - val_mae: 2.4344\n",
            "\n",
            "Epoch 00007: val_mae improved from 2.47551 to 2.43436, saving model to best_boston.h5\n",
            "Epoch 8/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 11.6246 - mae: 2.2908 - val_loss: 19.2255 - val_mae: 2.5471\n",
            "\n",
            "Epoch 00008: val_mae did not improve from 2.43436\n",
            "Epoch 9/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 11.4411 - mae: 2.2620 - val_loss: 15.7246 - val_mae: 2.3667\n",
            "\n",
            "Epoch 00009: val_mae improved from 2.43436 to 2.36670, saving model to best_boston.h5\n",
            "Epoch 10/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 11.0474 - mae: 2.1893 - val_loss: 15.4762 - val_mae: 2.7321\n",
            "\n",
            "Epoch 00010: val_mae did not improve from 2.36670\n",
            "Epoch 11/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 10.5965 - mae: 2.1727 - val_loss: 14.6872 - val_mae: 2.4198\n",
            "\n",
            "Epoch 00011: val_mae did not improve from 2.36670\n",
            "Epoch 12/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 10.9027 - mae: 2.1496 - val_loss: 13.0606 - val_mae: 2.3860\n",
            "\n",
            "Epoch 00012: val_mae did not improve from 2.36670\n",
            "Epoch 13/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 10.1326 - mae: 2.0807 - val_loss: 13.9228 - val_mae: 2.4626\n",
            "\n",
            "Epoch 00013: val_mae did not improve from 2.36670\n",
            "Epoch 14/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 10.4184 - mae: 2.1136 - val_loss: 13.2102 - val_mae: 2.3166\n",
            "\n",
            "Epoch 00014: val_mae improved from 2.36670 to 2.31664, saving model to best_boston.h5\n",
            "Epoch 15/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.9871 - mae: 2.0558 - val_loss: 14.1220 - val_mae: 2.5579\n",
            "\n",
            "Epoch 00015: val_mae did not improve from 2.31664\n",
            "Epoch 16/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.6110 - mae: 2.0816 - val_loss: 13.5309 - val_mae: 2.3483\n",
            "\n",
            "Epoch 00016: val_mae did not improve from 2.31664\n",
            "Epoch 17/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.8936 - mae: 2.0797 - val_loss: 13.8511 - val_mae: 2.2550\n",
            "\n",
            "Epoch 00017: val_mae improved from 2.31664 to 2.25502, saving model to best_boston.h5\n",
            "Epoch 18/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.3865 - mae: 2.0000 - val_loss: 12.3562 - val_mae: 2.1996\n",
            "\n",
            "Epoch 00018: val_mae improved from 2.25502 to 2.19956, saving model to best_boston.h5\n",
            "Epoch 19/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.1160 - mae: 2.0887 - val_loss: 13.6628 - val_mae: 2.2993\n",
            "\n",
            "Epoch 00019: val_mae did not improve from 2.19956\n",
            "Epoch 20/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 9.3014 - mae: 2.0138 - val_loss: 11.6154 - val_mae: 2.0701\n",
            "\n",
            "Epoch 00020: val_mae improved from 2.19956 to 2.07008, saving model to best_boston.h5\n",
            "Epoch 21/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.7003 - mae: 1.9422 - val_loss: 13.0877 - val_mae: 2.4038\n",
            "\n",
            "Epoch 00021: val_mae did not improve from 2.07008\n",
            "Epoch 22/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.8811 - mae: 2.0063 - val_loss: 11.7944 - val_mae: 2.1784\n",
            "\n",
            "Epoch 00022: val_mae did not improve from 2.07008\n",
            "Epoch 23/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.6725 - mae: 1.9496 - val_loss: 12.3615 - val_mae: 2.1741\n",
            "\n",
            "Epoch 00023: val_mae did not improve from 2.07008\n",
            "Epoch 24/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.5243 - mae: 2.0085 - val_loss: 12.0423 - val_mae: 2.1664\n",
            "\n",
            "Epoch 00024: val_mae did not improve from 2.07008\n",
            "Epoch 25/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.4491 - mae: 1.9385 - val_loss: 12.6351 - val_mae: 2.2460\n",
            "\n",
            "Epoch 00025: val_mae did not improve from 2.07008\n",
            "Epoch 26/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.3824 - mae: 1.9115 - val_loss: 10.7306 - val_mae: 2.2046\n",
            "\n",
            "Epoch 00026: val_mae did not improve from 2.07008\n",
            "Epoch 27/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.8747 - mae: 1.9104 - val_loss: 11.9952 - val_mae: 2.1275\n",
            "\n",
            "Epoch 00027: val_mae did not improve from 2.07008\n",
            "Epoch 28/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.9875 - mae: 1.9089 - val_loss: 13.9746 - val_mae: 2.3584\n",
            "\n",
            "Epoch 00028: val_mae did not improve from 2.07008\n",
            "Epoch 29/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.6132 - mae: 1.9313 - val_loss: 11.5848 - val_mae: 2.0411\n",
            "\n",
            "Epoch 00029: val_mae improved from 2.07008 to 2.04108, saving model to best_boston.h5\n",
            "Epoch 30/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.0866 - mae: 1.9489 - val_loss: 11.4263 - val_mae: 2.0781\n",
            "\n",
            "Epoch 00030: val_mae did not improve from 2.04108\n",
            "Epoch 31/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.8548 - mae: 1.9025 - val_loss: 12.4159 - val_mae: 2.2629\n",
            "\n",
            "Epoch 00031: val_mae did not improve from 2.04108\n",
            "Epoch 32/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.9670 - mae: 1.8530 - val_loss: 11.1164 - val_mae: 2.1553\n",
            "\n",
            "Epoch 00032: val_mae did not improve from 2.04108\n",
            "Epoch 33/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.9944 - mae: 1.7830 - val_loss: 11.5190 - val_mae: 2.1804\n",
            "\n",
            "Epoch 00033: val_mae did not improve from 2.04108\n",
            "Epoch 34/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 8.0691 - mae: 1.8986 - val_loss: 11.1667 - val_mae: 2.1205\n",
            "\n",
            "Epoch 00034: val_mae did not improve from 2.04108\n",
            "Epoch 35/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.7524 - mae: 1.8456 - val_loss: 12.6731 - val_mae: 2.3885\n",
            "\n",
            "Epoch 00035: val_mae did not improve from 2.04108\n",
            "Epoch 36/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.7407 - mae: 1.8891 - val_loss: 11.1478 - val_mae: 2.1661\n",
            "\n",
            "Epoch 00036: val_mae did not improve from 2.04108\n",
            "Epoch 37/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.9728 - mae: 1.8124 - val_loss: 10.8863 - val_mae: 2.1638\n",
            "\n",
            "Epoch 00037: val_mae did not improve from 2.04108\n",
            "Epoch 38/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.2256 - mae: 1.8714 - val_loss: 10.8887 - val_mae: 2.1058\n",
            "\n",
            "Epoch 00038: val_mae did not improve from 2.04108\n",
            "Epoch 39/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.3947 - mae: 1.7773 - val_loss: 10.6485 - val_mae: 2.1118\n",
            "\n",
            "Epoch 00039: val_mae did not improve from 2.04108\n",
            "Epoch 40/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.5010 - mae: 1.8142 - val_loss: 10.2817 - val_mae: 2.0382\n",
            "\n",
            "Epoch 00040: val_mae improved from 2.04108 to 2.03822, saving model to best_boston.h5\n",
            "Epoch 41/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.8505 - mae: 1.7123 - val_loss: 12.3529 - val_mae: 2.3044\n",
            "\n",
            "Epoch 00041: val_mae did not improve from 2.03822\n",
            "Epoch 42/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 7.1927 - mae: 1.8295 - val_loss: 12.1408 - val_mae: 2.2809\n",
            "\n",
            "Epoch 00042: val_mae did not improve from 2.03822\n",
            "Epoch 43/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.8439 - mae: 1.7564 - val_loss: 10.9763 - val_mae: 2.2817\n",
            "\n",
            "Epoch 00043: val_mae did not improve from 2.03822\n",
            "Epoch 44/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.6545 - mae: 1.7881 - val_loss: 11.7306 - val_mae: 2.2726\n",
            "\n",
            "Epoch 00044: val_mae did not improve from 2.03822\n",
            "Epoch 45/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.6925 - mae: 1.7749 - val_loss: 13.2762 - val_mae: 2.3109\n",
            "\n",
            "Epoch 00045: val_mae did not improve from 2.03822\n",
            "Epoch 46/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.6865 - mae: 1.7205 - val_loss: 11.1667 - val_mae: 2.1563\n",
            "\n",
            "Epoch 00046: val_mae did not improve from 2.03822\n",
            "Epoch 47/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.5923 - mae: 1.7487 - val_loss: 13.6212 - val_mae: 2.5416\n",
            "\n",
            "Epoch 00047: val_mae did not improve from 2.03822\n",
            "Epoch 48/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.5029 - mae: 1.7182 - val_loss: 12.2564 - val_mae: 2.2534\n",
            "\n",
            "Epoch 00048: val_mae did not improve from 2.03822\n",
            "Epoch 49/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.7209 - mae: 1.7056 - val_loss: 10.7891 - val_mae: 2.0400\n",
            "\n",
            "Epoch 00049: val_mae did not improve from 2.03822\n",
            "Epoch 50/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.2576 - mae: 1.7264 - val_loss: 11.3883 - val_mae: 2.1728\n",
            "\n",
            "Epoch 00050: val_mae did not improve from 2.03822\n",
            "Epoch 51/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.3303 - mae: 1.6737 - val_loss: 10.3201 - val_mae: 2.1483\n",
            "\n",
            "Epoch 00051: val_mae did not improve from 2.03822\n",
            "Epoch 52/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.2540 - mae: 1.6958 - val_loss: 10.0797 - val_mae: 2.0808\n",
            "\n",
            "Epoch 00052: val_mae did not improve from 2.03822\n",
            "Epoch 53/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.4296 - mae: 1.7135 - val_loss: 10.4630 - val_mae: 2.1182\n",
            "\n",
            "Epoch 00053: val_mae did not improve from 2.03822\n",
            "Epoch 54/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.8939 - mae: 1.6959 - val_loss: 13.0919 - val_mae: 2.4824\n",
            "\n",
            "Epoch 00054: val_mae did not improve from 2.03822\n",
            "Epoch 55/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.1349 - mae: 1.6924 - val_loss: 10.4729 - val_mae: 2.0691\n",
            "\n",
            "Epoch 00055: val_mae did not improve from 2.03822\n",
            "Epoch 56/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.8648 - mae: 1.6315 - val_loss: 12.9241 - val_mae: 2.2230\n",
            "\n",
            "Epoch 00056: val_mae did not improve from 2.03822\n",
            "Epoch 57/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.8815 - mae: 1.6547 - val_loss: 10.1614 - val_mae: 2.1112\n",
            "\n",
            "Epoch 00057: val_mae did not improve from 2.03822\n",
            "Epoch 58/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.0141 - mae: 1.6447 - val_loss: 10.2540 - val_mae: 2.1110\n",
            "\n",
            "Epoch 00058: val_mae did not improve from 2.03822\n",
            "Epoch 59/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.9180 - mae: 1.6029 - val_loss: 9.7047 - val_mae: 2.0010\n",
            "\n",
            "Epoch 00059: val_mae improved from 2.03822 to 2.00097, saving model to best_boston.h5\n",
            "Epoch 60/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 6.1414 - mae: 1.6354 - val_loss: 10.6367 - val_mae: 2.1339\n",
            "\n",
            "Epoch 00060: val_mae did not improve from 2.00097\n",
            "Epoch 61/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.6956 - mae: 1.6215 - val_loss: 10.1056 - val_mae: 2.0106\n",
            "\n",
            "Epoch 00061: val_mae did not improve from 2.00097\n",
            "Epoch 62/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.4745 - mae: 1.5592 - val_loss: 11.6547 - val_mae: 2.2237\n",
            "\n",
            "Epoch 00062: val_mae did not improve from 2.00097\n",
            "Epoch 63/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.5240 - mae: 1.5446 - val_loss: 11.9071 - val_mae: 2.2917\n",
            "\n",
            "Epoch 00063: val_mae did not improve from 2.00097\n",
            "Epoch 64/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.8040 - mae: 1.6082 - val_loss: 10.6449 - val_mae: 2.2848\n",
            "\n",
            "Epoch 00064: val_mae did not improve from 2.00097\n",
            "Epoch 65/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.8559 - mae: 1.5806 - val_loss: 10.2981 - val_mae: 2.2234\n",
            "\n",
            "Epoch 00065: val_mae did not improve from 2.00097\n",
            "Epoch 66/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.6142 - mae: 1.5714 - val_loss: 10.4982 - val_mae: 2.2750\n",
            "\n",
            "Epoch 00066: val_mae did not improve from 2.00097\n",
            "Epoch 67/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.6739 - mae: 1.5515 - val_loss: 11.3541 - val_mae: 2.3552\n",
            "\n",
            "Epoch 00067: val_mae did not improve from 2.00097\n",
            "Epoch 68/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.4270 - mae: 1.5376 - val_loss: 9.1856 - val_mae: 1.9516\n",
            "\n",
            "Epoch 00068: val_mae improved from 2.00097 to 1.95159, saving model to best_boston.h5\n",
            "Epoch 69/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.4558 - mae: 1.5774 - val_loss: 9.9216 - val_mae: 2.0744\n",
            "\n",
            "Epoch 00069: val_mae did not improve from 1.95159\n",
            "Epoch 70/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.3520 - mae: 1.5735 - val_loss: 10.2554 - val_mae: 2.1071\n",
            "\n",
            "Epoch 00070: val_mae did not improve from 1.95159\n",
            "Epoch 71/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.3766 - mae: 1.5021 - val_loss: 11.2023 - val_mae: 2.3656\n",
            "\n",
            "Epoch 00071: val_mae did not improve from 1.95159\n",
            "Epoch 72/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.9657 - mae: 1.4748 - val_loss: 16.0656 - val_mae: 2.9923\n",
            "\n",
            "Epoch 00072: val_mae did not improve from 1.95159\n",
            "Epoch 73/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.1689 - mae: 1.5589 - val_loss: 13.4661 - val_mae: 2.5625\n",
            "\n",
            "Epoch 00073: val_mae did not improve from 1.95159\n",
            "Epoch 74/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.0505 - mae: 1.5209 - val_loss: 10.8012 - val_mae: 2.2095\n",
            "\n",
            "Epoch 00074: val_mae did not improve from 1.95159\n",
            "Epoch 75/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.0625 - mae: 1.5539 - val_loss: 11.3411 - val_mae: 2.3431\n",
            "\n",
            "Epoch 00075: val_mae did not improve from 1.95159\n",
            "Epoch 76/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.0302 - mae: 1.5536 - val_loss: 11.6859 - val_mae: 2.3542\n",
            "\n",
            "Epoch 00076: val_mae did not improve from 1.95159\n",
            "Epoch 77/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.1987 - mae: 1.4841 - val_loss: 10.9655 - val_mae: 2.1640\n",
            "\n",
            "Epoch 00077: val_mae did not improve from 1.95159\n",
            "Epoch 78/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.0497 - mae: 1.4749 - val_loss: 11.8811 - val_mae: 2.3881\n",
            "\n",
            "Epoch 00078: val_mae did not improve from 1.95159\n",
            "Epoch 79/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.0512 - mae: 1.4989 - val_loss: 11.7449 - val_mae: 2.3944\n",
            "\n",
            "Epoch 00079: val_mae did not improve from 1.95159\n",
            "Epoch 80/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.0665 - mae: 1.4609 - val_loss: 12.4408 - val_mae: 2.3408\n",
            "\n",
            "Epoch 00080: val_mae did not improve from 1.95159\n",
            "Epoch 81/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 5.1342 - mae: 1.4330 - val_loss: 11.4076 - val_mae: 2.2884\n",
            "\n",
            "Epoch 00081: val_mae did not improve from 1.95159\n",
            "Epoch 82/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.6702 - mae: 1.4544 - val_loss: 13.0405 - val_mae: 2.3333\n",
            "\n",
            "Epoch 00082: val_mae did not improve from 1.95159\n",
            "Epoch 83/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.4611 - mae: 1.3622 - val_loss: 10.6390 - val_mae: 2.2808\n",
            "\n",
            "Epoch 00083: val_mae did not improve from 1.95159\n",
            "Epoch 84/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.6344 - mae: 1.4324 - val_loss: 10.3112 - val_mae: 2.1142\n",
            "\n",
            "Epoch 00084: val_mae did not improve from 1.95159\n",
            "Epoch 85/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.4876 - mae: 1.4094 - val_loss: 11.4969 - val_mae: 2.2597\n",
            "\n",
            "Epoch 00085: val_mae did not improve from 1.95159\n",
            "Epoch 86/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.7151 - mae: 1.5045 - val_loss: 14.1431 - val_mae: 2.6637\n",
            "\n",
            "Epoch 00086: val_mae did not improve from 1.95159\n",
            "Epoch 87/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.4369 - mae: 1.4143 - val_loss: 12.3805 - val_mae: 2.3191\n",
            "\n",
            "Epoch 00087: val_mae did not improve from 1.95159\n",
            "Epoch 88/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.6592 - mae: 1.4491 - val_loss: 11.6597 - val_mae: 2.2277\n",
            "\n",
            "Epoch 00088: val_mae did not improve from 1.95159\n",
            "Epoch 89/500\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 4.3502 - mae: 1.3520 - val_loss: 9.2900 - val_mae: 2.1092\n",
            "\n",
            "Epoch 00089: val_mae did not improve from 1.95159\n",
            "Epoch 90/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.4107 - mae: 1.4335 - val_loss: 12.7055 - val_mae: 2.4564\n",
            "\n",
            "Epoch 00090: val_mae did not improve from 1.95159\n",
            "Epoch 91/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.4613 - mae: 1.4358 - val_loss: 10.6051 - val_mae: 2.2506\n",
            "\n",
            "Epoch 00091: val_mae did not improve from 1.95159\n",
            "Epoch 92/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.4325 - mae: 1.4244 - val_loss: 10.7180 - val_mae: 2.2616\n",
            "\n",
            "Epoch 00092: val_mae did not improve from 1.95159\n",
            "Epoch 93/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.4189 - mae: 1.4180 - val_loss: 10.3938 - val_mae: 2.2086\n",
            "\n",
            "Epoch 00093: val_mae did not improve from 1.95159\n",
            "Epoch 94/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.9934 - mae: 1.3313 - val_loss: 10.6036 - val_mae: 2.1898\n",
            "\n",
            "Epoch 00094: val_mae did not improve from 1.95159\n",
            "Epoch 95/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.4156 - mae: 1.3532 - val_loss: 10.7437 - val_mae: 2.1976\n",
            "\n",
            "Epoch 00095: val_mae did not improve from 1.95159\n",
            "Epoch 96/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.2601 - mae: 1.3636 - val_loss: 12.1692 - val_mae: 2.3935\n",
            "\n",
            "Epoch 00096: val_mae did not improve from 1.95159\n",
            "Epoch 97/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.1709 - mae: 1.3919 - val_loss: 10.9986 - val_mae: 2.2918\n",
            "\n",
            "Epoch 00097: val_mae did not improve from 1.95159\n",
            "Epoch 98/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.4031 - mae: 1.3391 - val_loss: 11.1071 - val_mae: 2.3731\n",
            "\n",
            "Epoch 00098: val_mae did not improve from 1.95159\n",
            "Epoch 99/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.2109 - mae: 1.3727 - val_loss: 10.8890 - val_mae: 2.3196\n",
            "\n",
            "Epoch 00099: val_mae did not improve from 1.95159\n",
            "Epoch 100/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.1601 - mae: 1.3700 - val_loss: 10.5823 - val_mae: 2.1722\n",
            "\n",
            "Epoch 00100: val_mae did not improve from 1.95159\n",
            "Epoch 101/500\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 3.9405 - mae: 1.3263 - val_loss: 12.9037 - val_mae: 2.4790\n",
            "\n",
            "Epoch 00101: val_mae did not improve from 1.95159\n",
            "Epoch 102/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.9439 - mae: 1.3019 - val_loss: 14.9418 - val_mae: 2.8330\n",
            "\n",
            "Epoch 00102: val_mae did not improve from 1.95159\n",
            "Epoch 103/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.1732 - mae: 1.3607 - val_loss: 11.8301 - val_mae: 2.3498\n",
            "\n",
            "Epoch 00103: val_mae did not improve from 1.95159\n",
            "Epoch 104/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.6879 - mae: 1.3292 - val_loss: 10.4938 - val_mae: 2.3858\n",
            "\n",
            "Epoch 00104: val_mae did not improve from 1.95159\n",
            "Epoch 105/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.8696 - mae: 1.3133 - val_loss: 13.3489 - val_mae: 2.5846\n",
            "\n",
            "Epoch 00105: val_mae did not improve from 1.95159\n",
            "Epoch 106/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.9808 - mae: 1.3390 - val_loss: 11.9652 - val_mae: 2.4079\n",
            "\n",
            "Epoch 00106: val_mae did not improve from 1.95159\n",
            "Epoch 107/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.2543 - mae: 1.3583 - val_loss: 10.6017 - val_mae: 2.2991\n",
            "\n",
            "Epoch 00107: val_mae did not improve from 1.95159\n",
            "Epoch 108/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.6138 - mae: 1.3115 - val_loss: 12.9998 - val_mae: 2.6116\n",
            "\n",
            "Epoch 00108: val_mae did not improve from 1.95159\n",
            "Epoch 109/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.8447 - mae: 1.3319 - val_loss: 11.8612 - val_mae: 2.4041\n",
            "\n",
            "Epoch 00109: val_mae did not improve from 1.95159\n",
            "Epoch 110/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.6657 - mae: 1.2423 - val_loss: 11.8192 - val_mae: 2.3971\n",
            "\n",
            "Epoch 00110: val_mae did not improve from 1.95159\n",
            "Epoch 111/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.0736 - mae: 1.3458 - val_loss: 11.1690 - val_mae: 2.3650\n",
            "\n",
            "Epoch 00111: val_mae did not improve from 1.95159\n",
            "Epoch 112/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.7089 - mae: 1.2845 - val_loss: 13.4600 - val_mae: 2.6381\n",
            "\n",
            "Epoch 00112: val_mae did not improve from 1.95159\n",
            "Epoch 113/500\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 3.6295 - mae: 1.2462 - val_loss: 12.6983 - val_mae: 2.4947\n",
            "\n",
            "Epoch 00113: val_mae did not improve from 1.95159\n",
            "Epoch 114/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 4.1024 - mae: 1.3458 - val_loss: 10.8946 - val_mae: 2.2700\n",
            "\n",
            "Epoch 00114: val_mae did not improve from 1.95159\n",
            "Epoch 115/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.5456 - mae: 1.2620 - val_loss: 11.4564 - val_mae: 2.4002\n",
            "\n",
            "Epoch 00115: val_mae did not improve from 1.95159\n",
            "Epoch 116/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.6776 - mae: 1.2955 - val_loss: 11.9618 - val_mae: 2.4401\n",
            "\n",
            "Epoch 00116: val_mae did not improve from 1.95159\n",
            "Epoch 117/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.6858 - mae: 1.2782 - val_loss: 13.4093 - val_mae: 2.6518\n",
            "\n",
            "Epoch 00117: val_mae did not improve from 1.95159\n",
            "Epoch 118/500\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 3.8502 - mae: 1.2845 - val_loss: 13.6392 - val_mae: 2.7579\n",
            "\n",
            "Epoch 00118: val_mae did not improve from 1.95159\n",
            "Epoch 00118: early stopping\n",
            "CPU times: user 1min 32s, sys: 7.53 s, total: 1min 40s\n",
            "Wall time: 1min 29s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usCS9QcWPizG",
        "outputId": "9b650dbc-0442-462a-9bb3-ea47a1391fe9"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 76\n",
            "-rw-r--r-- 1 root root 70280 Aug  5 17:07 best_boston.h5\n",
            "drwxr-xr-x 1 root root  4096 Jul 16 13:20 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM-3Hpq_Pmqc",
        "outputId": "e58fd8d7-fa10-424f-f0bc-9921ca7bbbcc"
      },
      "source": [
        "test_mse_score, test_mae_score = boston.evaluate(X_test, y_test)\n",
        "\n",
        "print('MAE is : ', test_mae_score)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 18.3068 - mae: 3.0555\n",
            "MAE is :  3.055527925491333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}